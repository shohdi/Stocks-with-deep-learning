[defaults]
cuda=True
reload_config=False
env=ppaquette/DoomCorridor-v0
; how many steps to use in reward estimation
n_steps=10
; initial epsilon
epsilon=1.0
; epsilon decay after every epoch
epsilon_decay=0.995
; save interval in epoch
save_epoches=50
; count of games in the pool
env_pool_size=5
; convert image to grayscale, default=True
grayscale=True
; image width, default=80
image_width=80
; image height, default=80
image_height=80

[dqn]
copy_target_net_every_epoch=1
; use frozen network for target Q values
target_dqn=True
; chose target (last) action by basic model, but Q from frozen
double_dqn=True

[stop]
; stop after this mean reward for given amount of games, this is an optional param
mean_games=100
mean_reward=1000.0

[learning]
lr=0.001
batch_size=128

[exp_buffer]
; how many episodes we'll keep in buffer
size=10000
; how many entries we'll fetch every epoch
populate=200
